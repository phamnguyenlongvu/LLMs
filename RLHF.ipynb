{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNEovvUYf02z43Y9kMOnRYs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phamnguyenlongvu/LLMs/blob/main/RLHF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljt6iJNlJ5KY"
      },
      "outputs": [],
      "source": [
        "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 transformers==4.31.0 trl==0.5.0\n",
        "!pip install -q sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments\n",
        "from trl import RewardTrainer"
      ],
      "metadata": {
        "id": "nOqOhrcxKIUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)"
      ],
      "metadata": {
        "id": "6k-yrFeDQvvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"argilla/dolly-curated-comparison-falcon-7b-instruct\", split=\"train\")"
      ],
      "metadata": {
        "id": "_E4FcTFfQ1P2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = ds.to_pandas()\n",
        "df"
      ],
      "metadata": {
        "id": "I6g8yM-bRE7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "responses = [\"response-1\", \"response-2\"]\n",
        "\n",
        "def get_chosen_and_not_chosen(responses):\n",
        "  chosen_id = random.randint(0, len(responses) - 1)\n",
        "  not_chosen_id = 1 - chosen_id\n",
        "  return responses[chosen_id], responses[not_chosen_id], chosen_id\n",
        "\n",
        "rows = []\n",
        "\n",
        "for record in ds:\n",
        "  chosen, not_chosen, chosen_id = get_chosen_and_not_chosen(responses)\n",
        "  chosen_from_falcon, _, _ = get_chosen_and_not_chosen(responses)\n",
        "\n",
        "  rows.append(\n",
        "      {\n",
        "          \"instruction\": record[\"prompt\"],\n",
        "          \"chosen_response\": record[chosen],\n",
        "          \"rejected_response\": record[not_chosen]\n",
        "      }\n",
        "  )"
      ],
      "metadata": {
        "id": "KLY2tCBvRS65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_dataset = Dataset.from_list(rows)\n",
        "prepared_dataset.to_pandas()"
      ],
      "metadata": {
        "id": "xzJhkQvXTHal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_dataset"
      ],
      "metadata": {
        "id": "CvAP8k-_TVjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prepared_dataset_mini = prepared_dataset.select(range(1000))\n",
        "prepared_dataset_mini"
      ],
      "metadata": {
        "id": "NIsVvk2KTZ9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    BitsAndBytesConfig,\n",
        "    AutoTokenizer,\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(load_in_8bit=False, load_in_4bit=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                           quantization_config=quantization_config,\n",
        "                                                           device_map={\"\":0},\n",
        "                                                           trust_remote_code=True,\n",
        "                                                           num_labels=1)\n",
        "model.config.use_cache = False\n"
      ],
      "metadata": {
        "id": "hQ7sdIK7Tj5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token == None:\n",
        "  tokenizer.pad_token = tokenizer.eos_token\n",
        "  model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "def formatting_func(examples):\n",
        "  kwargs = {\n",
        "      \"padding\": \"max_length\",\n",
        "      \"truncation\": True,\n",
        "      \"max_length\": 256,\n",
        "      \"return_tensors\": \"pt\"\n",
        "  }\n",
        "\n",
        "  prompt_plus_chosen_response = (\n",
        "      examples[\"instruction\"] + \"\\n\" + examples[\"chosen_response\"]\n",
        "  )\n",
        "  prompt_plus_rejected_response = (\n",
        "      examples[\"instruction\"] + \"\\n\" +examples[\"rejected_response\"]\n",
        "  )\n",
        "\n",
        "  token_chosen = tokenizer.encode_plus(prompt_plus_chosen_response, **kwargs)\n",
        "  token_rejected = tokenizer.encode_plus(prompt_plus_rejected_response, **kwargs)\n",
        "\n",
        "  return {\n",
        "      \"input_ids_chosen\": token_chosen[\"input_ids\"][0],\n",
        "      \"attention_mask_chosen\": token_chosen[\"attention_mask\"][0],\n",
        "      \"input_ids_rejected\": token_rejected[\"input_ids\"][0],\n",
        "      \"attention_mask_rejected\": token_rejected[\"attention_mask\"][0]\n",
        "  }\n",
        "\n",
        "formatted_dataset = prepared_dataset_mini.map(formatting_func)\n",
        "formatted_dataset = formatted_dataset.train_test_split()"
      ],
      "metadata": {
        "id": "A9NC5PnGVYaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"True\""
      ],
      "metadata": {
        "id": "LhlQOnj0CvBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset[\"train\"]"
      ],
      "metadata": {
        "id": "KbZyocpzH_lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_dataset[\"train\"][\"instruction\"][1]"
      ],
      "metadata": {
        "id": "yF_wOtQpGvsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(formatted_dataset[\"train\"][\"input_ids_chosen\"][1])"
      ],
      "metadata": {
        "id": "o6AHgnU9H5uZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "from peft import LoraConfig\n",
        "from trl import RewardTrainer\n",
        "\n",
        "# Prepare training parameters\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./train_logs\",  # Output folder\n",
        "    max_steps=100,  # Maximum number of training steps\n",
        "    per_device_train_batch_size=4,  # Batch size per GPU for training\n",
        "    gradient_accumulation_steps=1,  # Number of steps to accumulate gradients\n",
        "    learning_rate=1.0e-4,  # Learning rate\n",
        "    optim=\"adamw_torch\",  # Optimizer\n",
        "    save_steps=50,  # How often to save checkpoints\n",
        "    logging_steps=10,  # How often to log training information\n",
        "    report_to=\"tensorboard\",  # Reporting method (in this case, TensorBoard)\n",
        "    remove_unused_columns=False,  # Whether to remove unused columns\n",
        "    evaluation_strategy=\"steps\",  # Evaluation strategy\n",
        "    num_train_epochs=5,  # Number of training epochs\n",
        ")\n",
        "\n",
        "# Prepare PEFT parameters\n",
        "peft_config = LoraConfig(\n",
        "    r=16,  # Value of r\n",
        "    lora_alpha=16,  # Value of lora_alpha\n",
        "    bias=\"none\",  # Bias setting\n",
        "    task_type=\"SEQ_CLS\",  # Task type (Sequence Classification)\n",
        "    modules_to_save=[\"scores\"],  # Modules to save\n",
        ")\n",
        "\n",
        "# Prepare RewardTrainer\n",
        "trainer = RewardTrainer(\n",
        "    model=model,  # The model for reinforcement learning\n",
        "    tokenizer=tokenizer,  # The tokenizer for processing input data\n",
        "    args=training_args,  # Training arguments\n",
        "    train_dataset=formatted_dataset[\"train\"],  # Training dataset\n",
        "    eval_dataset=formatted_dataset[\"test\"],  # Evaluation dataset\n",
        "    peft_config=peft_config,  # PEFT configuration\n",
        "    max_length=512,  # Maximum length of input\n",
        ")\n",
        "\n",
        "# Execute training\n",
        "trainer.train()\n",
        "\n",
        "# Save the pretrained reward model\n",
        "trainer.model.save_pretrained(\"./reward_model\")"
      ],
      "metadata": {
        "id": "lizV-PYwAPiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def get_Score(model, tokenizer, prompt, response):\n",
        "  inputs = tokenizer.encode_plus(\n",
        "      prompt,\n",
        "      response,\n",
        "      truncation=True,\n",
        "      padding=\"max_length\",\n",
        "      max_length=512,\n",
        "      return_tensors=\"pt\"\n",
        "  ).to(\"cuda:0\")\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs=model(**inputs)\n",
        "\n",
        "  logits = outputs.logits\n",
        "\n",
        "  return logits.item()\n"
      ],
      "metadata": {
        "id": "OcbALMzPBVe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = 1000\n",
        "prepared_dataset[x]"
      ],
      "metadata": {
        "id": "YgsLkrAJEF6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prepared_dataset[x][\"instruction\"]\n",
        "rejected_response = prepared_dataset[x][\"rejected_response\"]\n",
        "chosen_response = prepared_dataset[x][\"chosen_response\"]\n",
        "\n",
        "print(prompt)\n",
        "print(rejected_response)\n",
        "print(chosen_response)"
      ],
      "metadata": {
        "id": "--XsemEcELeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = get_Score(model, tokenizer, prompt, rejected_response)\n",
        "score"
      ],
      "metadata": {
        "id": "wpHCOg5AEg2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = get_Score(model, tokenizer, prompt, chosen_response)\n",
        "score"
      ],
      "metadata": {
        "id": "qMKfuHDhEoJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = prepared_dataset.shuffle().select(range(500))"
      ],
      "metadata": {
        "id": "_VfPrkquIf2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rs = []\n",
        "\n",
        "for record in test_dataset:\n",
        "  prompt = record[\"instruction\"]\n",
        "  rejected_response = record[\"rejected_response\"]\n",
        "  chosen_response = record[\"chosen_response\"]\n",
        "\n",
        "  rejected_score = get_Score(model, tokenizer, prompt, rejected_response)\n",
        "  chosen_score = get_Score(model, tokenizer, prompt, chosen_response)\n",
        "\n",
        "  rs.append({\n",
        "      \"prompt\": prompt,\n",
        "      \"rejected_response\": rejected_response,\n",
        "      \"chosen_response\": chosen_response,\n",
        "      \"rejected_score\": rejected_score,\n",
        "      \"chosen_score\": chosen_score\n",
        "  })"
      ],
      "metadata": {
        "id": "6hXYfpWvIcqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(rs)\n",
        "df"
      ],
      "metadata": {
        "id": "GtTY42GfLk0q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}